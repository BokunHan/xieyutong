import asyncio
import re
from datetime import datetime, date
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode


def extract_prices_from_markdown(markdown_content, url=""):
    """
    ä»åŠ è½½åçš„markdownå†…å®¹ä¸­ï¼Œæå–æ‰€æœ‰ç­æœŸçš„ä»·æ ¼ä¿¡æ¯
    """
    print("ğŸ¯ å¼€å§‹ä»markdownä¸­æå–ä»·æ ¼æ—¥å†...")

    product_id_match = re.search(r'productid=(\d+)', url, re.IGNORECASE)
    product_id = product_id_match.group(1) if product_id_match else ""

    prices = []
    current_year = ""
    current_month = ""
    today = date.today()
    lines = markdown_content.split('\n')

    calendar_loaded = any(re.search(r'\d{4}å¹´\d{1,2}æœˆ', line) for line in lines)
    if not calendar_loaded:
        print("âš ï¸ è­¦å‘Š: æœªåœ¨é¡µé¢å†…å®¹ä¸­æ‰¾åˆ°ä»·æ ¼æ—¥å†ç»“æ„ã€‚JSç‚¹å‡»å¯èƒ½æœªæˆåŠŸã€‚")
        return {"product_id": product_id, "prices": [],
                "metadata": {"extracted_at": datetime.now().isoformat(), "source_url": url,
                             "error": "Calendar data not found."}}

    for line in lines:
        line = line.strip()
        month_header_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ', line)
        if month_header_match:
            current_year, current_month = month_header_match.groups()
            current_month = current_month.zfill(2)
            continue

        price_line_match = re.search(r'(\d{1,2})Â¥(\d+)', line)
        if price_line_match and current_year and current_month:
            day, price_str = price_line_match.groups()
            day = day.zfill(2)

            try:
                current_date = date(int(current_year), int(current_month), int(day))
                if current_date < today:
                    continue

                prices.append({
                    "date": current_date.isoformat(),
                    "price": int(price_str)
                })
            except ValueError:
                continue

    print(f"âœ… ä»·æ ¼æå–å®Œæˆï¼å…±æ‰¾åˆ° {len(prices)} ä¸ªæœ‰æ•ˆç­æœŸã€‚")
    return {"product_id": product_id, "prices": prices,
            "metadata": {"extracted_at": datetime.now().isoformat(), "source_url": url}}


async def crawl_and_extract_prices(url):
    """
    æœ€ç»ˆç‰ˆ: ä½¿ç”¨JSå†…ç½®å»¶æ—¶æ¥ç¡®ä¿åœ¨ç¨³å®šçŠ¶æ€ä¸‹æ‰§è¡Œç‚¹å‡»
    """
    print(f"ğŸš€ å¼€å§‹çˆ¬å–ä»·æ ¼æ—¥å† (0.7.4 æœ€ç»ˆå…¼å®¹æ¨¡å¼): {url}")

    browser_config = BrowserConfig(
        # browser_type="chromium",
        headless=True,
        # verbose=True,
        extra_args=['--disable-web-security']
        # user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E183 Safari/604.1"
    )

    # å”¯ä¸€æœ‰æ•ˆçš„å»¶æ—¶å‚æ•°æ˜¯ delay_before_return_html
    # æˆ‘ä»¬å°†åœ¨JSå†…éƒ¨å¤„ç†å‰ç½®å»¶æ—¶
    crawl_config = CrawlerRunConfig(
        cache_mode=CacheMode.BYPASS,
        delay_before_return_html=6.0,
        scan_full_page=True,
        log_console=True,
        verbose=True,
        js_code="""
            async function stableClick() {
                console.log('--- JS SCRIPT STARTED ---');
                
                // å…³é”®æ­¥éª¤: å¢åŠ å‰ç½®ç­‰å¾…æ—¶é—´åˆ°5ç§’ï¼Œç¡®ä¿æ‰€æœ‰äº‹ä»¶ç›‘å¬å™¨éƒ½å·²é™„åŠ 
                console.log('Waiting 3 seconds for page to fully stabilize...');
                await new Promise(resolve => setTimeout(resolve, 3000));
                console.log('Page should be stable now. Looking for button...');

                const targetButton = document.querySelector('.ScheduleDetailMoreText');
                if (targetButton) {
                    console.log('>>> Button FOUND. Simulating a real user click...');
                    
                    // å…³é”®æ”¹åŠ¨ï¼šåˆ›å»ºä¸€ä¸ªçœŸå®çš„é¼ æ ‡äº‹ä»¶å¹¶æ´¾å‘å®ƒ
                    const clickEvent = new MouseEvent('click', {
                        view: window,
                        bubbles: true,
                        cancelable: true
                    });
                    targetButton.dispatchEvent(clickEvent);
                    
                    console.log('>>> Click event dispatched!');
                } else {
                    console.log('!!! ERROR: Button .ScheduleDetailMoreText not found.');
                }
                console.log('--- JS SCRIPT FINISHED ---');
            }
            stableClick();
            """
    )

    async with AsyncWebCrawler(config=browser_config) as crawler:
        try:
            print("ğŸ“± æ­£åœ¨åŠ è½½é¡µé¢å¹¶æ‰§è¡ŒJS...")
            result = await crawler.arun(url=url, config=crawl_config)

            if result.success and result.markdown:
                print("âœ… é¡µé¢çˆ¬å–æˆåŠŸï¼")
                structured_data = extract_prices_from_markdown(result.markdown, url)
                return {"success": True, "data": structured_data}
            else:
                print(f"âŒ é¡µé¢çˆ¬å–å¤±è´¥: {result.error_message}")
                return {"success": False, "error": f"çˆ¬å–å¤±è´¥: {result.error_message}"}

        except Exception as e:
            print(f"ğŸ’¥ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            return {"success": False, "error": f"å‘ç”Ÿå¼‚å¸¸: {str(e)}"}